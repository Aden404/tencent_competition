{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练集和测试集特征分离后   baseline : 0.713741"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、单独加入广告发布的不同用户数，0.716053，效果有较大提升\n",
    "\n",
    "2、加入广告的出现次数，0.713612,效果下降\n",
    "\n",
    "2、加入广告点击率和广告发布的不同用户数， 0.714031, 效果下降。。\n",
    "\n",
    "2、加入campaign的点击率，0.715376，效果下降\n",
    "\n",
    "3、加入用户所在LBS的历史点击率, 效果下降。。\n",
    "\n",
    "4、加入用户的兴趣总数，0.714661，效果下降。。\n",
    "\n",
    "5、加入用户的历史接收的广告次数与历史点击次数，以及历史点击率, 效果均下降\n",
    "\n",
    "6、分析广告投放和地理位置的关系\n",
    "\n",
    "7、加入每个地理位置的人数特征, 效果下降\n",
    "\n",
    "8、考虑点击相同广告的用户的interest2分布,在点击的用户中，某个兴趣id出现次数是总人数的三分之一则保留"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('./datasets/train_data.csv')\n",
    "target = pd.read_csv('./datasets/train_target.csv', names=['label'], header=None)\n",
    "\n",
    "data.drop(data.columns[[0]], axis=1, inplace=True)  #删除某列函数\n",
    "target = target.reset_index(drop=True)\n",
    "\n",
    "one_hot_feature=['creativeSize', 'LBS','age','carrier','consumptionAbility', 'education','gender','house','os','marriageStatus','advertiserId','campaignId', 'creativeId',\n",
    "       'adCategoryId', 'productId', 'productType']\n",
    "vector_feature=['interest1','interest2','interest5','kw1','kw2','topic1','topic2']\n",
    "\n",
    "\n",
    "\n",
    "for feature in one_hot_feature:\n",
    "    try:\n",
    "        data[feature] = LabelEncoder().fit_transform(data[feature].apply(int))\n",
    "    except:\n",
    "        data[feature] = LabelEncoder().fit_transform(data[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, np.array(target).squeeze(), random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clicked = X_train[y_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理联网类型特征\n",
    "ct_train = X_train['ct'].values\n",
    "ct_train = [m.split(' ') for m in ct_train]\n",
    "ct_trains = []\n",
    "for i in ct_train:\n",
    "    index = [0, 0, 0, 0, 0]\n",
    "    for j in i:\n",
    "        index[int(j)] = 1\n",
    "    ct_trains.append(index)\n",
    "\n",
    "ct_test = X_test['ct'].values\n",
    "ct_test = [m.split(' ') for m in ct_test]\n",
    "ct_tests = []\n",
    "for i in ct_test:\n",
    "    index = [0, 0, 0, 0, 0]\n",
    "    for j in i:\n",
    "        index[int(j)] = 1\n",
    "    ct_tests.append(index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加每个广告点击率特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ad = X_train['aid'].value_counts().sort_index()\n",
    "num_ad_clicked = data_clicked['aid'].value_counts().sort_index()\n",
    "\n",
    "ratio = num_ad_clicked / num_ad\n",
    "\n",
    "ratio_clicked = pd.DataFrame({\n",
    "    'aid': ratio.index,\n",
    "    'ratio_clicked' : ratio.values\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.merge(X_train, ratio_clicked, on=['aid'], how='left')\n",
    "X_test = pd.merge(X_test, ratio_clicked, on=['aid'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加每个广告出现次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ad_post = X_train['aid'].value_counts().sort_index()\n",
    "\n",
    "num_ad_post = pd.DataFrame({\n",
    "    'aid': num_ad_post.index,\n",
    "    'num_ad_post' : num_ad_post.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.merge(X_train, num_ad_post, on=['aid'], how='left')\n",
    "X_test = pd.merge(X_test, num_ad_post, on=['aid'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加每个广告推送给不同的用户数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_advertise_touser = X_train.groupby('aid').uid.nunique()\n",
    "num_advertise_touser = pd.DataFrame({\n",
    "    'aid': num_advertise_touser.index,\n",
    "    'num_advertise_touser' : num_advertise_touser.values\n",
    "})\n",
    "X_train = pd.merge(X_train, num_advertise_touser, on=['aid'], how='left')\n",
    "X_test = pd.merge(X_test, num_advertise_touser, on=['aid'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入推广计划转化率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_campaign = X_train['campaignId'].value_counts().sort_index()\n",
    "num_campaign_clicked = data_clicked['campaignId'].value_counts().sort_index()\n",
    "\n",
    "ratio_num_campaign = num_campaign_clicked / num_campaign\n",
    "\n",
    "ratio_num_campaign = pd.DataFrame({\n",
    "    'campaignId': ratio_num_campaign.index,\n",
    "    'ratio_num_campaign' : ratio_num_campaign.values\n",
    "})\n",
    "X_train = pd.merge(X_train, ratio_num_campaign, on=['campaignId'], how='left')\n",
    "X_test = pd.merge(X_test, ratio_num_campaign, on=['campaignId'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入用户兴趣总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_interest = X_train[['interest1', 'interest2', 'interest5', 'kw1', 'kw2', 'topic1', 'topic2']]\n",
    "test_all_interest = X_test[['interest1', 'interest2', 'interest5', 'kw1', 'kw2', 'topic1', 'topic2']]\n",
    "num_all_interest_train = []\n",
    "num_all_interest_test = []\n",
    "aids = []\n",
    "train_array = np.array(train_all_interest)\n",
    "test_array = np.array(test_all_interest)\n",
    "\n",
    "for i in range(train_array.shape[0]):\n",
    "    num = 0\n",
    "    inter = train_array[i]\n",
    "    for j in inter:\n",
    "        inter_lis = j.split(' ')\n",
    "        if inter_lis[0] == '-1':\n",
    "            continue\n",
    "        num += len(inter_lis)\n",
    "    num_all_interest_train.append(num)\n",
    "    \n",
    "    \n",
    "for i in range(test_array.shape[0]):\n",
    "    num = 0\n",
    "    inter = test_array[i]\n",
    "    for j in inter:\n",
    "        inter_lis = j.split(' ')\n",
    "        if inter_lis[0] == '-1':\n",
    "            continue\n",
    "        num += len(inter_lis)\n",
    "    num_all_interest_test.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_all_interest_train = pd.DataFrame(num_all_interest_train, columns=['num_all_interest'])\n",
    "num_all_interest_test = pd.DataFrame(num_all_interest_test, columns=['num_all_interest'])\n",
    "\n",
    "X_train = pd.concat([X_train, num_all_interest_train], axis=1)\n",
    "X_test = pd.concat([X_test, num_all_interest_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入地理位置所对应的用户人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lbs_user = X_train.groupby('LBS').uid.nunique()\n",
    "num_lbs_user = pd.DataFrame({\n",
    "    'LBS': num_lbs_user.index,\n",
    "    'num_lbs_user' : num_lbs_user.values\n",
    "})\n",
    "X_train = pd.merge(X_train, num_lbs_user, on=['LBS'], how='left')\n",
    "X_test = pd.merge(X_test, num_lbs_user, on=['LBS'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入用户所在LBS的历史点击率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lbs = X_train.groupby('LBS').uid.nunique()\n",
    "num_lbs_clicked = data_clicked.groupby('LBS').uid.nunique()\n",
    "ratio_num_lbs = num_lbs_clicked / num_lbs\n",
    "ratio_num_lbs = ratio_num_lbs.fillna(0)\n",
    "ratio_num_lbs = pd.DataFrame({\n",
    "    'LBS': ratio_num_lbs.index,\n",
    "    'ration_num_LBS' : ratio_num_lbs.values\n",
    "})\n",
    "X_train = pd.merge(X_train, ratio_num_lbs, on=['LBS'], how='left')\n",
    "X_test = pd.merge(X_test, ratio_num_lbs, on=['LBS'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入用户的历史接收的广告次数与历史点击次数，以及历史点击率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user_getad = X_train.groupby('uid').aid.nunique().sort_index()\n",
    "num_user_clicked = data_clicked.groupby('uid').aid.nunique().sort_index()\n",
    "\n",
    "num_user_getad = pd.DataFrame({\n",
    "    'uid': num_user_getad.index,\n",
    "    'num_user_getad' : num_user_getad.values\n",
    "})\n",
    "\n",
    "num_user_clicked = pd.DataFrame({\n",
    "    'uid': num_user_clicked.index,\n",
    "    'num_user_clicked' : num_user_clicked.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.merge(X_train, num_user_getad, on=['uid'], how='left')\n",
    "X_test = pd.merge(X_test, num_user_getad, on=['uid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.merge(X_train, num_user_clicked, on=['uid'], how='left')\n",
    "X_test = pd.merge(X_test, num_user_clicked, on=['uid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[['num_advertise_touser'\n",
    "                        ]].values)\n",
    "X_train_encoded = scaler.transform(X_train[['num_advertise_touser'\n",
    "                                                 ]].values)\n",
    "\n",
    "X_test_encoded = scaler.transform(X_test[['num_advertise_touser'\n",
    "                                                  ]].values)\n",
    "\n",
    "X_train_encoded= np.hstack((X_train_encoded, ct_trains))\n",
    "X_test_encoded= np.hstack((X_test_encoded, ct_tests))\n",
    "\n",
    "\n",
    "# X_train_encoded = ct_trains\n",
    "# X_test_encoded = ct_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "oc_encoder = OneHotEncoder()\n",
    "for feature in one_hot_feature:\n",
    "    oc_encoder.fit(X_train[feature].reshape(-1, 1))\n",
    "    train_a=oc_encoder.transform(X_train[feature].values.reshape(-1, 1))\n",
    "    X_train_encoded = sparse.hstack((X_train_encoded, train_a))\n",
    "    test_a=oc_encoder.transform(X_test[feature].values.reshape(-1, 1))\n",
    "    X_test_encoded = sparse.hstack((X_test_encoded, test_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(615917, 1177)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_feature=['interest1','interest2_new', 'interest5','kw1','kw2','topic1','topic2']\n",
    "ct_encoder = CountVectorizer(min_df=0.0009)\n",
    "for feature in vector_feature:\n",
    "    ct_encoder.fit(X_train[feature])\n",
    "    train_a = ct_encoder.transform(X_train[feature])\n",
    "    X_train_encoded = sparse.hstack((X_train_encoded, train_a))\n",
    "    test_a = ct_encoder.transform(X_test[feature])\n",
    "    X_test_encoded = sparse.hstack((X_test_encoded, test_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = np.array(target).squeeze()\n",
    "clf = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=0.9,\n",
    "        max_depth=-1, n_estimators=500, objective='binary',\n",
    "        subsample=0.7, colsample_bytree=0.8, subsample_freq=1,\n",
    "        learning_rate=0.05, min_child_weight=60, random_state=2018, n_jobs=-1\n",
    "    )\n",
    "clf.fit(X_train_encoded, y_train, eval_set=[(X_test_encoded, y_test)], eval_metric='auc',early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user_clicksameAd_interest = data_clicked.groupby('aid').interest2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_adid = data_clicked['aid'].value_counts().sort_index().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_interest2 = {}\n",
    "for adid in num_adid:\n",
    "    dict_buf = {}\n",
    "    for interest in num_user_clicksameAd_interest.items():\n",
    "        index = interest[0]\n",
    "        if index[0] == adid:\n",
    "            number = interest[1]\n",
    "            detail = index[1]\n",
    "            detail = detail.split(' ')\n",
    "            for det in detail:\n",
    "                if det not in dict_buf:\n",
    "                    dict_buf[det] = number\n",
    "                else:\n",
    "                    dict_buf[det] += number\n",
    "    dict_interest2[adid] = dict_buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_aid_clicked = dict(data_clicked['aid'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_common_interest2 = []\n",
    "for adid, dict_inter in dict_interest2.items():\n",
    "    dict_common_buf = {}\n",
    "    dict_common_buf['aid'] = adid\n",
    "    common_inter = []\n",
    "    ad_total = num_ad_clicked[adid] - dict_inter.get('-1', 0)\n",
    "    if '-1' in dict_inter:\n",
    "        dict_inter.pop('-1')\n",
    "    for id_inter, num in dict_inter.items():\n",
    "            if num >= ad_total/4:\n",
    "                common_inter.append(id_inter)\n",
    "    dict_common_buf['common_interest2'] = common_inter\n",
    "    dict_common_interest2.append(dict_common_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common_interest2 = pd.DataFrame(dict_common_interest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.merge(X_train, df_common_interest2, on=['aid'], how='left')\n",
    "X_test = pd.merge(X_test, df_common_interest2, on=['aid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_interest2 = X_train[['interest2', 'common_interest2']]\n",
    "test_user_interest2 = X_test[['interest2', 'common_interest2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interest2_new = []\n",
    "for i in train_user_interest2.values:\n",
    "    inter2_buf = []\n",
    "    int2 = i[0].split(' ')\n",
    "    common = i[1]\n",
    "    for det in int2:\n",
    "        if det in common:\n",
    "            inter2_buf.append(det)\n",
    "    inter2_buf.extend(int2)\n",
    "    train_interest2_new.append(inter2_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interest2_new = []\n",
    "for i in test_user_interest2.values:\n",
    "    inter2_buf = []\n",
    "    int2 = i[0].split(' ')\n",
    "    common = i[1]\n",
    "    for det in int2:\n",
    "        if det in common:\n",
    "            inter2_buf.append(det)\n",
    "    inter2_buf.extend(int2)\n",
    "    test_interest2_new.append(inter2_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interest2_new = [' '.join(m) for m in train_interest2_new]\n",
    "X_train['interest2_new'] = train_interest2_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('interest_new', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interest2_new = [' '.join(m) for m in test_interest2_new]\n",
    "X_test['interest2_new'] = test_interest2_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
